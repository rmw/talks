# Shadow User Flows and Rethinking Data Integrity

## Format

* Full talk
* Lightning Talk

## Abstract
Does forcing someone to input one of two gender options actually give you an accurate picture of the gender of your users? When users create their own "shadow user flow" outside the system what does that mean for the reportings and analysis that come out of that data? What does it mean for policy, promotions, or national security?

Today we live in an asynchronous, primarily digital world that uses the data we create to theorize, model, and influence the people around us. What does data integrity look like when data is everywhere?

### 300 words

If we require someone to choose between two genders, does that give us an accurate picture of our users? Users often create their own "shadow user flow" outside the system. How does that effect the policy and decisions the come out of that data?  It's time to rethink data integrity.


## Description
How many forms have you written that “require” a user to input a piece of data? How does that effect the amount and correctness of the data you receive? Does forcing someone to input one of two gender options actually give you accurate data on the gender of your users? What does data integrity look like when data is cheap, easy, and everywhere?

After extensive user research utlizing human centered design
and service design on a project, we found a "shadow user flow" happening outside of
the software we were looking to rebuild.  This "Shadow User Flow" was
information written on paper that moved from employee to employee and
was seen as more accurate than the data stored in the software. 

This is not the first time I've seen this and it won't be the last. This hacking of the process means higher level reports and analysis are inherently wrong.  What happens when that data and anlysis is used to make impactful decisions about raises, investment, promotions, government policy, and national security?

In the 70s, when relational databases were being developed, there was a lot of focus on “Data Normalization” or techniques to reduce data redundancy and ensure correctness. This is a legacy of synchronous systems and the philosophy that having correct data was more important than having some data. But today we live in an asynchronous, primarily digital world with event streams, multiple endpoints, highly interactive front-ends, and many types of databases. We live in world that uses the data we create to theorize, model, and influence the people around us.



## Why Me

My company has been working on a rewriting a government system build in 1994. We have done extensive user research and found that there’s a “shadow user flow” of information written on paper that flows around the office. This got me thinking about traditional models of data integrity, redundancy, and validation.  These models fail us as the software we create becomes essential to human interaction and the data we create is used by many, many forces to make far reaching decisions. Let’s talk about how we view data integrity and how we can reframe that concept to better function in today’s world.


## Audience
* Engineers
* Engineering Management
* Product Managers

## Outcomes/Conclusions
* History of how we think about data integrity
* Tools for analysing the "shadow user flow" that exists behind their
  software
* Ideas and techniques for managing data validation
* New frameworks for thinking about data input

## Outline


## Submitted to


## Given at
